# 微软“二十一世纪的计算大会”

##一、创新的核心：基础研究 （Peter Lee）

----------


###1.一些话
> 　　今天的计算机研究每天都在发现新的东西，而这些东西往往是一些精彩的理论。但与此同时这些研究也非常实用，最终都是帮助人们过上更好的生活。因此，一个有趣的现象是世界各地的大学和顶尖公司都在投入大量的人力物力从事计算机的基础研究。
> 　　像苹果，Facebook这样的大型科技公司正在纷纷建立主要的研究实验室。甚至Uber这样的初创公司在逐步变大时，他们也会在研究上投入金钱，物力。为什么呢？这就是本次讲座的主题。
> 　　科技行业比以往更依赖研究。

　　Peter提到，为了推动计算机行业的持续高速发展，不仅要从事软件研究，也要反思硬件的局限性，发明更新型的硬件体系结构。这几年，微软在硬件方面的投入很多，包括用FPGA武装云计算的数据中心。FPGA是一种非常灵活的低功耗硬件，可以适应丰富的计算需求。我们研究院最近做了很多关于如何利用FPGA来加速深度学习的工作，让硬件的研究和人工智能研究无缝接轨。
> 数据中心的维护费用耗资巨大，如何降低服务器降温过程中的能耗问题十分关键。微软研究院的Project Natick项目创新地把数据中心置入大海，利用寒冷的海水冷却服务器，并用海浪为之提供电能，还可能减少近海大城市数据传输的延迟。

----------


###2.机器学习相关
　　除了云计算之外，大数据和算法的进步也格外重要。特别是**机器学习算法**对人工智能的推动作用。

> 刘铁岩：我所在的机器学习组最近也在关注神经机器翻译，我们在今年的NIPS上发表了一篇通过增强学习(reinforcement learning)技术、从无标签数据中自动获得翻译能力的论文，它利用了机器翻译的对偶结构，取得了非常好的翻译精度。我们把这项技术成为Dual learning（对偶学习）。有兴趣的同学们可以关注一下 ：）

论文网址：https://arxiv.org/abs/1611.00179


> 英语里有一个单词Serendipity，意思是偶然发生的快乐事件。这对于研究来说，时常发生。当你开始研究一些东西，最终很有可能得到一些意想不到的精彩，这意味着我们需要对意想不到的事件保持开放心态。

一些例子：

- 机器学习也正在为计算机赋予“看”的能力。只需要访问https://www.captionbot.ai/ 上传照片，我们的系统就能“看到”并向你“解释”看到了什么。
- Microsoft Cognitive Toolkit （微软认知工具包）链接：https://www.microsoft.com/en-us/research/product/cognitive-toolkit/ 
- 【开源】微软发布认知工具包：让机器学习更快、更大、更强 https://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&mid=2649439195&idx=1&sn=09afaeac1861e4175d9854796f96f19e&chksm=82c0d25fb5b75b49c6aa6700729421715a3da5236c7af711de9c747f4b30aeb2c90193c1e241&mpshare=1&scene=1&srcid=1103W3uqBdZgBdUHOJi6seiN&pass_ticket=OXajMLUoGQf5TSgwil%2BQcxZHhv3pn61RrqBk55v952fwHh0OKm553ZOykYs975jt#rd
- 微软认知服务：人工智能的技术拼图（各种API） https://mp.weixin.qq.com/s?__biz=MzAwMTA3MzM4Nw==&mid=401938749&idx=1&sn=9bbb0e1b9c8bd18aa4239fbbee21bf7e&mpshare=1&scene=1&srcid=1103UXUHJJxHCHe36sV8njIy&pass_ticket=OXajMLUoGQf5TSgwil%2BQcxZHhv3pn61RrqBk55v952fwHh0OKm553ZOykYs975jt#rd
- 基于微软认知服务开发的人脸识别应用 http://how-old.net/ 


----------

###3.小结
　　Peter的报告结束了。Peter提到了推动人工智能研究和产业发展的三个重要因素：超大规模的计算能力、无处不在的大数据、机器学习尤其是深度学习算法和理论的发展。可以说，我们这一代研究人员站在了一个难得的历史机遇面前，希望我们能够借力于这些因素，把人工智能推向一个新的高度。
　　展望人工智能进一步的发展，其实还有很长的路要走。有很多高级的人工智能问题，包括语义理解、无监督学习，都不是简单地使用更多计算资源、从更大的数据中、学习更复杂的深度神经网络，就能解决的。这些应用呼唤着新的创新破土而出。
> 我们研究院最近有几个工作，正是沿着这样的研究思路开展的。比如刚刚发表在NIPS上的Dual Learning方法，就是利用AI任务之间的内在关系，为无监督数据创造有效的反馈闭环，从而实现有效的学习；另外一篇同样发表在NIPS上的LightRNN算法，就是要告诉大家有时精巧的算法设计可能会带来比蛮力并行训练更大的收益。
> 我们最近在整理一套轻量级的快速有效的机器学习算法，其中包括去年发表的LightLDA算法，今年发表的LightRNN和LightGBM等，这些算法都会陆续开源到微软机器学习工具包DMTK里，欢迎大家试用，也欢迎大家加入到四两拨千斤的人工智能研发中来。


##二、Co-Evolution of Artificial Intelligence and Human Intelligence（洪小文）

> 洪小文博士现任微软全球资深副总裁，微软亚太研发集团主席，兼微软亚洲研究院院长，全面负责推动微软在亚太地区的科研及产品开发战略，以及与中国及亚太地区学术界的合作。
> 洪小文博士师从图灵奖获得者拉吉·瑞迪（RajReddy），而拉吉·瑞迪则是人工智能领域的奠基人和拓荒者约翰·麦卡锡（John McCarthy）的学生。洪小文博士从事人工智能相关研究近30年，是国际公认的语音识别专家。

　　我们现有的资源与之前可谓不同日而语——部署在云端的海量计算资源已经像水和电一样唾手可得了；互联网所容纳的信息也远远超过了过去几千年来人们所有的知识储备；以深度学习等为代表的机器学习算法的发展，也让计算机能够从这些庞大的数据中获取知识。
　　小文指出，人类智能的优越性在于从小样本中、甚至0样本中进行学习和推理。而以深度学习为代表的人工智能技术则更适合从大数据中学习。

----------
###1.人工智能中的“智能”究竟指什么呢？
　　他将智能分为四个阶段：
　　
　　 1. 第一级，**功能（Capability）**。功能是工具的价值点，对于人类最有意义，也一直推动着人类社会的进步。从石刀石斧、鼎镬簋盂、埙筝钟磬到今天的跑车、游轮、客机，工具万千，各有所用。
　　 2. 第二级，**智能（Intelligence**）。有趣的是，“智能”的概念是跟着时代的发展而不断改变的。记忆力是一种智能吗？倒退几百年的话，显然是。科举、八股文所考察的首先是应试者对古老经典全局与细节的记忆。算术是一种智能吗？曾经是——《水浒传》里有位好汉叫神算子蒋敬，职司梁山钱粮支出纳入，可说是梁山一百单八将里少见的头脑与肌肉兼具的人才。下棋是一种智能吗？当然是。雄踞国际象棋第一高手宝座时间最长的棋手加里-卡斯珀罗夫曾被誉为“全世界最聪明的人”——但在今天，说起记忆力、算数和弈棋（不包括围棋），计算机比人类更在行，但大部分人可能不会认为这些有多高智能多了不起。另外，IQ（Intelligence Quotient）测试是个有趣的话题——由于测试全程通常都会给出各种选项，机器在应对这种智能商数的挑战时其实是有很大的几率得高分的，我猜测，未来十年内，将会出现IQ测试拿最高分的机器。
　　 3. 第三级，**智力（Intellect）**。智力比智能更高一筹，“力”这个字里包含了判断力、创造力等信息。对人类来说，每天我们面对的大多都不是选择题，又或是有着无穷选项的选择题。例如，我在微软亚洲研究院的日常工作，大部分都不是非此即彼的选择——一个研究团队需要补充人手，我不能简单地回答“可以”或“不可以”，而是要结合实际情况，包括预算、课题、团队现状、发展前景等多方面的因素，来判断团队是否真的急需补人、补多少人和什么样的人，或者是否可以通过与其他组的合并来内部解决。今天的AI，基本上没有能力在缺乏数据的情况下，创造出如天外飞来一笔的新的选项。
　　 4. 第四级，**智慧（Wisdom）**。智慧往往是由丰富阅历、深邃思考积淀而来的洞察——所以我们经常说某位长者智慧深广、堪为导师。所有的智能都不是用选项的形式来表述的，就像火种，它能在特定的时刻引燃人们思想的火花，照映前路。哪怕再过很久很久，机器也不大可能产生真正的智慧。

###2.现状和未来
　　截至目前，全世界最“聪明”的机器也只是站在了第二级台阶上——AI这个概念的大部分含义其实是“功能”，还有一定的“智能”。“智能”与“智力”只差一个字，但对机器而言却好像是鸿沟天堑，极难攀越——至于让机器具备“智慧”，剧作家和导演当然会继续开发此类题材的科幻电影，但科学家们所得到的进展却微乎其微。
　　洪小文博士认为，机器进化至今，已堪称无人能匹敌的“最强左脑”，可是机器也有着明显的极限和天花板，那便是它们从未发展出右脑能力——至少截至目前，没有任何迹象显示，机器能以某种形式像人类右脑那样进行创新和创造。人脑认知后通常会举一反三，拥有无穷的创造力。图像识别、语音识别也是一样。机器能分辨猫和狗，能根据用户语音指令查询天气、订购外卖，但这并不代表机器真真拥有智能了。
　　总之，人类发明的计算机可以成为最好的左脑，而人类自身则继续保有最好的右脑。机器没可能也没必要取代人类，因此，HI+AI（也就是人类智能+人工智能）、创新算法+计算才是潜力无限的组合，才是人工智能走向更强之路的最佳途径。就是“共进化” Co-Evolution
　　

----------


##三、一些有用的问题

###1.deep learning应用
　　问：为什么现在的deep learning主要用在NLP和CV的任务里面，而其他的领域比如说fierier她的城市计算的project里面就没有用到？是因为NLP和CV最好出成果还是这两个最重要？
　　
　　答：其实deep learning最强的地方就在于用深层网络去拟合非常复杂的分类界面（虽然也有用神经网络做回归和数据生成的）。从这意义上讲，要发挥deep Learning的威力，需要非常大的有标注的训练数据。在CV领域deep Learning之所以最近这几年非常火，要归功于ImageNet、COCO这样的大规模有标注数据集的构建。在NLP领域，也有很多大数据，如大语种的双语语料现在都能到几千万个句对。
　　可是反观城市大数据分析，虽然数据量非常大，但是很多数据是无标记的。我们的目标不是学习分类界面，而是寻找数据里的潜在规律。这主要是无监督学习任务，不是深度学习的大本营。当我前面也提到，在城市计算的某些子问题上，还是可以使用深度学习的。

----------

###2.强化学习
　　问：现在强化学习在机器人控制、自动驾驶、推荐系统中有很多应用。目前看上去无监督学习例如聚类等等方法能力和还是比较有限，监督性学习又需要大量标记数据的背景下，是不是像强化学习这样天生就有“自学”能力的方法会越来越热门？此外，我看到刘老师组里做的基于强化学习的无监督机器翻译，我想问下那强化学习未来还可能会应用到哪些问题上，会有怎样的发展？
　　
　　答：我也认为强化学习是一个很有前途的研究方向。但是，它变得这么火，也就是这几年的事情。记得去年NIPS的RL workshop上，有教授感叹前几年他们的学生都找不到工作，现在成了抢手货。
　　我觉得强化学习变得很受重视，确实和人工智能的发展阶段有很大关系。当很多有监督的问题（如图像识别、语音识别等模式识别问题）都可以用深度学习（部分）解决以后，人们开始关注一些更难的问题，尤其是那些没有直接的监督信息、需要自学的问题。
　　强化学习需要从环境中获取有效的（延时）反馈信号。有些问题的反馈信号是自然存在的，比如围棋或video game的胜负，但是有些问题需要我们自己巧妙地设计反馈信号，才能更好地指导增强学习的过程。
　　我们今年在NIPS上发表的论文，关注的点就是如何利用AI任务的对偶属性定义有效的反馈信号。当然有的时候，可能很难像我们的工作那样显示定义出反馈信号，那就需要通过inverse RL来学习合理的反馈。这一点对于实际的复杂应用尤为重要。我个人觉得增强学习下一步的重点是怎么从实验室和游戏室走出来，真正探索出一套鲁棒的，解决实际复杂问题的框架。

----------
###3.AI人才
　　问：在人工智能这个大的产业链上，学术界和产业界对人才有着怎样的需求，及相关人才的培养包括人才的自我塑造和成长等等？
　　
　　答：在这个人工智能的时代，技术发展的速度太快了。我觉得这种大背景对人才的要求首先是非常强的学习能力。这种学习能力，不仅体现在读书上，也体现在实践的能力上。所谓活到老学到老，有这种态度，其实各种知识都不难学、各种工具都不难掌握。我还记得和CMU的Jamie Callan讨论的时候，他说过作为一个教授，每五年都需要跟着学生重新读一遍PhD。我想也是同样的道理。
　　除此之外，如果说到要掌握的知识和技能，我想可以分几个层次。首先是同学们在学校里一定要把数学基础打好，因为你今后的职业道路上可能会转换一些方向甚至行业，所谓学好数理化、走遍全天下，有坚实的数学技术，可以很快地进入新的领域。
　　其次，要对机器学习、优化论（连续和组合）、近似算法有比较多的了解。因为人工智能的很多问题最终都会归结成优化问题，并需要设计高效的算法来解决这些优化问题
　　再次，要有非常好的实现能力。人工智能的研究离不开对大数据的处理，所以还要熟练使用一些用于处理大数据、训练模型的开源工具。这样才有实战的能力。
　　有了上面这些知识和技能，我觉得即便是在瞬息万变的人工智能领域，应该也可以应付自如了。